{
 "metadata": {
  "name": "",
  "signature": "sha256:99b1aba54a2a0c16e19150c9ea4d2ea688f815d11522ca8afff43f39e554b1a0"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Initialization"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%autosave 0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "History Object (thing to load in data saved by patcher)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Usage"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nitpick.fileIO import History"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First create a history object for a particular file path"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "h=History()\n",
      "#or h = History('/path/to/saved/data')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Then call whatever piece you want. Use tab autocomplete to see them all."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "h.inputDimensions()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "[25, 25]"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print h.activeColumns()[:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[1, 6, 30, 46, 47, 55, 56, 61, 65, 77, 78, 82, 84, 87, 100, 101, 104, 105, 120, 121, 127, 135, 136, 137, 148, 149, 155, 156, 158, 170, 200, 233, 265, 274, 300, 313, 338, 341, 377, 395], [2, 17, 65, 83, 97, 98, 102, 133, 136, 138, 141, 165, 167, 173, 193, 194, 202, 203, 205, 213, 220, 222, 239, 250, 258, 294, 304, 307, 313, 326, 329, 330, 331, 335, 350, 353, 354, 372, 386, 391], [20, 41, 56, 80, 96, 97, 98, 126, 128, 146, 155, 168, 170, 185, 186, 189, 200, 202, 203, 205, 212, 228, 232, 244, 247, 265, 268, 271, 272, 286, 307, 313, 324, 347, 350, 359, 361, 372, 378, 397], [28, 30, 66, 89, 98, 129, 135, 136, 149, 158, 167, 173, 174, 180, 184, 193, 200, 202, 203, 205, 209, 212, 213, 215, 238, 244, 247, 250, 251, 265, 268, 272, 273, 287, 290, 307, 313, 328, 329, 372], [3, 17, 55, 56, 66, 72, 101, 129, 133, 138, 141, 149, 152, 154, 157, 166, 167, 173, 193, 265, 268, 272, 287, 288, 294, 296, 313, 329, 334, 335, 350, 353, 354, 359, 370, 372, 378, 383, 397, 399]]\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Implementation Notes"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "``History(modelID).activeColumns()``\n",
      "    \n",
      " - creates data fetcher class\n",
      " - init sets the path to the files\n",
      " - this class has functions that fetch lists of the data\n",
      " \n",
      "patcher function when run, creates a history instance and attches it to the sp instance\n",
      "\n",
      "    spInstance.History.activeColumns()\n",
      " you can use tab autocomplete to see the available data(loading functions)\n",
      " \n",
      "####Notes\n",
      "\n",
      " - The aim with this was to make it as thin as possible - don't do any processing of the data, just load it in, in the same way it was saved            \n",
      " - loading the proximal synapses takes a while, might be an idea to change everything to use numpy arrays\n",
      " - It feels like there is a lot of almost repeated code in the patcher. Is ther a better way of doing things?\n",
      " - It would be nice to have a powerful way of slicing and dicing the data - for example a easy way to get a list of all the SDR's produced by a particular category of input, or an easy way to get the history of the synapses connected to one column.\n",
      " - IDEA: it would be useful to have a 'describe' function like pandas, that prints out a summary of what has been saved, with file sizes."
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Patcher"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Usage"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nitpick.fileIO import Patcher"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Create a spatial pooler and patch it"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nupic.research.spatial_pooler import SpatialPooler"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sp = SpatialPooler(\n",
      "                   inputDimensions=[25, 25],\n",
      "                   columnDimensions=[20, 20],\n",
      "                   potentialRadius=4,\n",
      "                   potentialPct=0.5,\n",
      "                   synPermInactiveDec=0.1,\n",
      "                   synPermActiveInc=0.1,\n",
      "                   synPermConnected=0.1,\n",
      "                   localAreaDensity=0.1,\n",
      "                   numActiveColumnsPerInhArea=-1,\n",
      "                   globalInhibition=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "p=Patcher()\n",
      "p.patchSP(sp)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Then call whatever piece you need"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sp.history.dimensions()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "[20, 20]"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Implementation Notes"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "When you import fileIO, the Patcher from cerebro2 is imported and modified.  \n",
      "It adds a history object onto the sp, tp, and model instances.\n",
      "\n",
      "The patcher is currently fairly slow on big models.\n",
      "\n",
      "Thoughts on a redesign:\n",
      " - Maybe use pandas and HDF5 - high speed and desined for handling huge sets of data and supports compression\n",
      " - It might be possible to make the patcher more general - a universal patcher that you can just pass some kind of config file to that will set it up to save and load the state of any kind of model."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}